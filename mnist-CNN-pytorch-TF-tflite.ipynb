{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From PyTorch to TensorFlow to Coral TPU\n",
    "## Introduction\n",
    "### In this article, I will show you how to convert a PyTorch model to a TensorFlow model and run a TensorFlow model on a Coral TPU. To demonstrate this, I will test the model on a dataset of handwritten digits called mnist. Also, you should know Python and some PyTorch.  This is the link for the original model in PyTorch: https://github.com/neel-kumar/deep-learning-mnist/blob/master/mnist-CNN.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import tflite_runtime.interpreter as tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_jpg(filename):\n",
    "    return Image.open(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_jpg(a, filename):\n",
    "    ia = (a * 255).astype(np.uint8)\n",
    "    ia = np.reshape(ia, (28,28))\n",
    "    Image.fromarray(ia).save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_img(a, dim=(28, 28)):\n",
    "    img = np.reshape(a, dim)\n",
    "    imgplot = plt.imshow(img, cmap = \"gray\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU found\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/37660312/how-to-run-tensorflow-on-cpu\n",
    "\n",
    "# Uncomment following to disable GPU\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "if tf.test.gpu_device_name():\n",
    "    print('GPU found')\n",
    "else:\n",
    "    print(\"No GPU found\")\n",
    "\n",
    "print(tf.test.gpu_device_name())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras Model\n",
    "### TensorFlow includes an API, called Keras, which helps you build high level Neural Networks. This means that you only have to specify a few things, and the rest it taken care by the computer. I did this because Keras provided me with all of the controls I could need while not being that complicated. Alright, now lets go through the model in the cell just below. If you want to see the original model go to the link at the top. The model is inside of a function because we can call the function to create the model (as is done in cell 7).\n",
    "### Now lets look at the model. First, we give it a name which is in this case \"mnist-CNN-tf\".Then we can add all the other layers to create the final model. This is what each of the lines do:\n",
    "- Line 2: Create the model and give it a name\n",
    "- Line 3: Conv2D\n",
    "- Line 4: Average Pool\n",
    "- Line 5: Conv2D\n",
    "- Line 6: Flattens the layer\n",
    "- Line 7: Dense is a linear layer\n",
    "- Line 8: Dense is output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = models.Sequential(name = \"mnist-CNN-tf\")\n",
    "    model.add(layers.Conv2D(8, 3, padding = 'same', activation='relu', input_shape=(28, 28, 1), name = \"layer1\"))\n",
    "    model.add(layers.AveragePooling2D((2, 2), name = \"layer2\"))\n",
    "    model.add(layers.Conv2D(13, 3, padding = 'same', activation='relu', name = \"layer3\"))\n",
    "    model.add(layers.Flatten(name = \"layer4\"))\n",
    "    model.add(layers.Dense(14*14*13, name = \"layer5\"))\n",
    "    model.add(layers.Dense(10, name = \"layer6\"))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mnist-CNN-tf\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "layer1 (Conv2D)              (None, 28, 28, 8)         80        \n",
      "_________________________________________________________________\n",
      "layer2 (AveragePooling2D)    (None, 14, 14, 8)         0         \n",
      "_________________________________________________________________\n",
      "layer3 (Conv2D)              (None, 14, 14, 13)        949       \n",
      "_________________________________________________________________\n",
      "layer4 (Flatten)             (None, 2548)              0         \n",
      "_________________________________________________________________\n",
      "layer5 (Dense)               (None, 2548)              6494852   \n",
      "_________________________________________________________________\n",
      "layer6 (Dense)               (None, 10)                25490     \n",
      "=================================================================\n",
      "Total params: 6,521,371\n",
      "Trainable params: 6,521,371\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splits the mnist data set\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "x_train = x_train.reshape(-1, 28, 28, 1)\n",
    "x_test = x_test.reshape(-1, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=loss_fn, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-01 10:09:42.492059\n",
      "Epoch 1/2\n",
      "938/938 [==============================] - 71s 75ms/step - loss: 0.2850 - accuracy: 0.9160 - val_loss: 0.0608 - val_accuracy: 0.9808\n",
      "Epoch 2/2\n",
      "938/938 [==============================] - 70s 74ms/step - loss: 0.0545 - accuracy: 0.9828 - val_loss: 0.0443 - val_accuracy: 0.9852\n",
      "2022-11-01 10:12:03.704944\n"
     ]
    }
   ],
   "source": [
    "# Running the model for 20 epochs with a batch size of 64\n",
    "print(datetime.now())\n",
    "model.fit(x_train, y_train, epochs=2, batch_size=64, validation_data=(x_test, y_test))\n",
    "print(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_test[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([7, 2, 1, 0, 4, 1, 4, 9, 5, 9], dtype=int64),\n",
       " array([7, 2, 1, 0, 4, 1, 4, 9, 5, 9], dtype=uint8))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.argmax(axis=1), y_test[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFlite\n",
    "### Alright, now on to TensorFlow Lite, or TFlite for short, the function below converts a TensorFlow model into a TFlite file which can be run on the TPU (Tensor Processing Unit). A TPU is just a smaller version of a GPU that is made to run Tensors. The small size of this device allows you to use AI in spaces where you can't fit a proper GPU. Since the TPU is so small it will obviously be much less powerful than a proper GPU, but is is powerful enough to significantly augment a CPU's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\PROF~1.WKM\\AppData\\Local\\Temp\\tmp38y7mjny\\assets\n"
     ]
    }
   ],
   "source": [
    "def convert_to_tflite(model, filename):\n",
    "    # Convert the tensorflow model into a tflite file.\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    tflite_model = converter.convert()\n",
    "\n",
    "    # Save the model.\n",
    "    with open(filename, 'wb') as f:\n",
    "        f.write(tflite_model)\n",
    "\n",
    "mnist_tflite_filename = \"mnist.tflite\"\n",
    "convert_to_tflite(model, mnist_tflite_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[WinError 126] The specified module could not be found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-db51cfa8e933>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minterpreter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0minterpreter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_tflite_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmnist_tflite_filename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-15-db51cfa8e933>\u001b[0m in \u001b[0;36mload_tflite_model\u001b[1;34m(modelpath)\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m# Load using TPU\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     interpreter = tflite.Interpreter(model_path=modelpath,\n\u001b[1;32m----> 7\u001b[1;33m                                      experimental_delegates=[tflite.load_delegate('libedgetpu.so.1')])\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0minterpreter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mallocate_tensors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minterpreter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tfvirt\\lib\\site-packages\\tflite_runtime\\interpreter.py\u001b[0m in \u001b[0;36mload_delegate\u001b[1;34m(library, options)\u001b[0m\n\u001b[0;32m    150\u001b[0m   \"\"\"\n\u001b[0;32m    151\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 152\u001b[1;33m     \u001b[0mdelegate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDelegate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlibrary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    153\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m     raise ValueError('Failed to load delegate from {}\\n{}'.format(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tfvirt\\lib\\site-packages\\tflite_runtime\\interpreter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, library, options)\u001b[0m\n\u001b[0;32m     79\u001b[0m                          'due to missing immediate reference counting.')\n\u001b[0;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_library\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpydll\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLoadLibrary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlibrary\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m     self._library.tflite_plugin_create_delegate.argtypes = [\n\u001b[0;32m     83\u001b[0m         \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPOINTER\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_char_p\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tfvirt\\lib\\ctypes\\__init__.py\u001b[0m in \u001b[0;36mLoadLibrary\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    424\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    425\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mLoadLibrary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 426\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dlltype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    427\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    428\u001b[0m \u001b[0mcdll\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLibraryLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCDLL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tfvirt\\lib\\ctypes\\__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode, handle, use_errno, use_last_error)\u001b[0m\n\u001b[0;32m    346\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 348\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_dlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    349\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    350\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 126] The specified module could not be found"
     ]
    }
   ],
   "source": [
    "def load_tflite_model(modelpath):\n",
    "    # Load the TFLite model and allocate tensors.\n",
    "    # Load using CPU\n",
    "    # interpreter = tf.lite.Interpreter(model_path=modelpath)\n",
    "    # Load using TPU\n",
    "    interpreter = tflite.Interpreter(model_path=modelpath,\n",
    "                                     experimental_delegates=[tflite.load_delegate('libedgetpu.so.1')])\n",
    "    interpreter.allocate_tensors()\n",
    "    return interpreter\n",
    "\n",
    "interpreter = load_tflite_model(mnist_tflite_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Model on the TPU\n",
    "### Since we created the TFlite file and loaded it onto the TPU lets run it! The function below sets up a few things before running the model on the TPU, and we can see the model is able to properly identify the image as a 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tflite_predict(interpreter, data):\n",
    "    input_data = data.reshape(1, 28, 28, 1).astype(np.float32)\n",
    "    interpreter.set_tensor(interpreter.get_input_details()[0]['index'], input_data)\n",
    "    interpreter.invoke()\n",
    "    return interpreter.get_tensor(interpreter.get_output_details()[0]['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = tflite_predict(interpreter, x_test[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.argmax(1), y_test[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_img(x_test[9])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
